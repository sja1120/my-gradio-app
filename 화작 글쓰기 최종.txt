 현재 우리나라에는 2026년 1월 시행 예정인 인공지능기본법이 제정되어 있다. 이는 인공지능의 건전한 발전과 신뢰 기반 조성에 필요한 기본적인 사항을 규정한 것으로, 국민의 권익과 존엄성을 보호하고 국민의 삶의 질 향상과 국가경쟁력을 강화하는 데 이바지함을 목적으로 한다.  그중 인공지능기본법 제2조 4호에서 다루고 있는 “고영향 인공지능”을 주의 깊게 보려 한다. 인공지능기본법 제2조 4호에는 고영향 인공지능이란 사람의 생명, 신체의 안전 및 기본권에 중대한 영향을 미치거나 위험을 초래할 우려가 있는 인공지능시스템이라고 정의되어 있다. 그러나 여기서 말하는 ‘중대한 영향‘이나 ’위험‘은 무엇을 의미하는지 알 수 없어 상당한 모호성을 띤다. 이는 사람들에게 큰 혼란을 줄 뿐만 아니라, 인공지능 발전에도 부정적인 영향을 미칠 수 있다. 따라서 이 글을 통해 고영향 인공지능의 정의에 대해 비판적으로 다뤄보고자 한다. 
 먼저 고영향 인공지능이라는 개념이 모호한 이유는 앞에서 언급했듯이 어디까지가 ’중대한 영향’ 및 ’위험‘인지 알 수 없기 때문이다. 예를 들어 의료 분야에서 사용되는 인공지능의 경우 사람의 생명과 관련되어 있기 때문에 고영향 인공지능으로 볼 수 있다. 하지만 채용, 교육과 같은 분야에서 사용되는 인공지능은 생명에 직접적으로 영향을 주지는 않지만, 인공지능을 사용하였을 때 그 결과가 어떻게 활용되는지에 따라 위험에 대한 해석이 달라질 수 있어 고영향으로 분류하기에 모호하다.
 이처럼 명확한 기준 없이 주관적으로 판단하게 된다면, 어디까지를 위험으로 규제할 것인지 결정하기 어려워진다. 이러한 모호성은 인공지능 관련 산업, 기술 발전 등에 부정적인 영향을 줄 수 있다. 인공지능 사업자 입장에서 본다면, 어떤 기술이 고영향 인공지능에 해당하는지 명확히 알 수 없기 때문에 혁신적인 기술보다는 안전한 기술 개발을 우선시할 수 있다. 이는 인공지능 산업 위축과 같은 문제를 불러올 수 있으며, 나아가 국제 경쟁에서 뒤처지는 결과를 초래할 수 있다. 타국의 사례를 살펴보면 고영향 인공지능을 분류하는 기준이 우리나라와 확연히 다른 것을 알 수 있다. 유럽 연합(EU)은 인공지능의 위험도를 4단계(허용 불가능한 위험, 고위험, 제한적 위험, 최소 위험)로 분류한 EU AI 법을 2024년 3월에 최종 승인하였고, 이 법은 단계적으로 시행될 예정이다. EU AI 법은 각 단계에 따라 규제를 다르게 적용하여 교육, 고용 등 구체적인 분야를 명시하고, 각 분야에 해당하는 조건도 상세히 정리하였다. 우리나라도 이처럼 분야별로 고영향 인공지능의 기준을 세분화하고, 관련 예시를 제시한다면 혼란을 줄일 수 있을 것이다.
 위 내용과 같이 고영향 인공지능의 정의가 모호할 경우 여러 문제가 발생할 수 있다. 따라서 ‘중대한 영향‘ 및 ’위험‘이 무엇을 의미하는지 구체적으로 제시하여 사람들에게 혼란을 주지 않도록 법을 개정해야 한다. 고영향 인공지능의 정의가 구체화된다면, 개발자와 기업은 법적 기준을 더 명확하게 이해하고 이에 맞게 기술을 개발할 수 있다. 이러한 변화는 우리에게 더욱 안전하고 편리한 인공지능 기술을 가져다주고, 더불어 인간과 인공지능이 함께 성장하는 바람직한 미래를 만들어 줄 것이다.