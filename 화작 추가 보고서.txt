비판적 글쓰기 활동에서 인공지능기본법의 모호성에 대해 다룬 뒤, 고영향 인공지능의 기준이 불분명할 때 어떤 문제가 생길 수 있는지 더 깊이 탐구하고 싶었다. 특히 최근 자율주행차, 배달 로봇 등과 같은 자율 시스템의 활용이 늘어나고 있는데, 이것이 고영향 인공지능으로 분류되는지는 인공지능기본법이 실제 현장에 어떻게 적용될 수 있을지를 판단하는 데 핵심적인 요소가 된다고 생각했다. 따라서 이번 탐구 에서는 자율 시스템이 고영향 인공지능에 해당하는지, 그렇다면 어떤 기준과 보완이 필요한지를 살펴보고자 한다.

먼저 자율 시스템이 사람의 생명과 안전에 얼마나 영향을 미치는지에 대해 알아보았다. 최근 자율주행차나 배달로봇 등 인공지능 기술을 활용한 이동 수단이 실제 도로에서 사고를 일으킨 사례들이 있었다. 신호를 인식하지 못한 로봇이 보행자와 충돌하거나, 시야 확보가 어려운 어두운 환경에서 자율주행차가 사고를 낸 경우 등이 대표적이다. 이러한 사고들은 자율 시스템이 단순한 편의 기술을 넘어 직접적으로 사람의 생명과 신체에 영향을 줄 수 있음을 보여준다. 이는 인공지능기본법 제2조 4호에서 말하는 ‘고영향 인공지능’의 정의에 부합할 가능성이 있다는 뜻이다.

현재 자율주행 기술은 특성상 고영향 인공지능으로 분류될 수 있다는 의견이 제기되고 있으며, 관련 논의가 이어지고 있다. 이는 자율 시스템이 제도적으로도 일정 수준의 위험성과 영향력을 가진 기술로 인식되고 있다는 것을 보여준다. 하지만 문제는 여전히 고영향 인공지능의 기준이 명확하지 않다는 것이다. 예를 들어 의료 분야는 생명과 관련이 있어 고영향 인공지능으로 보기 쉽지만, 자율 시스템은 어느 수준의 사고 가능성이나 영향력이 있어야 고영향으로 볼 수 있는지 불분명하다.

만약 자율 시스템이 고영향 인공지능으로 분류된다면 단순히 기술을 규제하는 것이 아니라 정교한 기준과 제도가 마련되어야 한다. 예를 들어 자율 시스템의 사고 발생 가능성, 사고 시 예상 피해 규모, 사용 환경 등을 종합적으로 고려하여 고영향 여부를 판단하는 체크리스트나 분류 체계를 도입하는 것이 필요하다. 또한 사고가 발생했을 때의 책임 소재를 명확히 하고, 이에 따른 보상 제도도 함께 정비되어야 한다.

자율 시스템은 사람의 생명과 안전에 직접적인 영향을 줄 수 있는 만큼 고영향 인공지능으로 분류될 가능성이 충분하다. 따라서 이를 둘러싼 법적 정의와 규제 기준은 더욱 명확하고 세분화되어야 하며, 기술 발전과 안전 사이의 균형을 이루기 위한 제도적 보완이 필요하다. 이러한 방향으로 제도가 발전한다면, 우리는 자율 시스템을 안전하게 활용하면서도 더 신뢰할 수 있는 인공지능 사회를 만들어갈 수 있을 것이다.